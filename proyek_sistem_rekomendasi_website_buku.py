# -*- coding: utf-8 -*-
"""Proyek_Sistem_Rekomendasi_Website_Buku.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rO99hbqW4-giEDnSCN0XjoEcxHO8xJOa

# Proyek Sistem Rekomendasi Buku
- **Nama:** Abid Juliant Indraswara
- **Email:** abidjuliant@gmail.com
- **ID Dicoding:** abidindraswara

Proyek ini berfokus pada pengembangan sistem yang mampu merekomendasikan buku untuk pembaca buku. Rekomendasi buku bisa dari berbagai hal tergantung data-data buku maupun data-data para pembaca buku yang saling relevan.

## Project Overview

Latar Belakang

Buku merupakan perantara manusia dalam menyampaikan segala hal sejak jaman dahulu hingga sekarang. Bentuknya pun seiring waktu berubah namun tidak menghilangkan esensinya dalam menyampaikan perasaan, pengetahuan dan sejenisnya. Masih diminati hingga saat ini oleh para pembaca buku dari berbagi genre baik berbentuk fisik maupun online. Buku bisa ditemui dimana saja termasuk online yang tentunya memudahkan akses para pembaca baik untuk membacanya maupun membeli nya[\[1\]](https://doi.org/10.1109/ICISC47916.2020.9171222). Teknologi berkembang pesat dengan hadirnya internet dan sekarang di dukung dengan AI baik para pembaca buku untuk menemukan buku maupun penjual buku atau juga penulis buku[\[2\]](https://doi.org/10.1109/SAPIENCE.2016.7684166).

Berbagai jenis buku tersedia dan distribusikan secara online yang jumlahnya sangat banyak serta dengan bahasa yang berbeda. Timbul beberapa masalah dari beberapa pembaca untuk dapat menemukan buku yang orisinil, kualitas fisik/ isi bagus, dengan genre yang sesuai pembaca, berdasarkan kriteria penulis yang disuka, rating yang bagus dan masih banyak lagi membuat para pembaca kebingungan menentukan pilihannya[\[1\]](https://doi.org/10.1109/ICISC47916.2020.9171222). Melalui bantuan AI pilihan-pilihan tersebut dapat dipersingkat dengan menggunakan sistem saran atau rekomendasi sehingga pembaca mudah menentukan pilihannya. Beberapa pilihan yang sulit dan banyak akan dipersingkat hanya dengan melakukan beberapa aksi kecil yang umumnya di lakukan secara online. Rekomendasi sederhana dari buku yang paling populer, buku yang laris di pasaran, buku yang memiliki review atau rating terbaik, buku yang baru saja rilis dan masih banyak lagi[\[2\]](https://doi.org/10.1109/SAPIENCE.2016.7684166). Itu baru awal ketika baru saja akses ke website khusus konten jual buku, namun ketika sudah menjadi anggota dari website tersebut melalui riwayat dari yang dibaca maupun data pengguna maka rekomendasi yang muncul akan berbeda seperti genre buku yang sering dibaca, berdasarkan penulis dan sejenisnya. Tidak dipungkiri teknologi ini memudahkan serta menguntungkan kedua belah pihak pembaca buku, penulis buku dan penjual buku[\[3\]](https://doi.org/10.1109/IAdCC.2014.6779375).

Sistem rekomendasi bukan alat yang baru di era modern ini, karena banyak digunakan untuk merekomendasikan produk yang paling sesuai kepada pengguna atau pembaca buku. Persaingan di era modern yang begitu ketat mendorong semua pihak khususnya para penjual untuk dapat menambah atau meningkatkan keuntungan dan juga mempertahankan para pengguna jasa website khusus konten jual buku[\[3\]](https://doi.org/10.1109/IAdCC.2014.6779375). Sistem rekomendasi buku harus dapat merekomendasikan buku yang sesuai dengan minat pembeli. Terdapat banyak jenis rekomendasi sistem yang digunakan. Sehingga dalam upaya peningkatan keuntungan, kemudahan penggemar atau pembaca buku dan mempertahankan para pengguna jasa penyedia jual buku maka sistem rekomendasi merupakan solusi yang tepat untuk digunakan. Oleh karena itu pada projek ini akan membuat sistem rekomendasi dengan metode Content Based Filtering menggunakan pendekatan item yang cocok bagi pengguna.

## Business Understanding

Permasalahn yang terjadi dalam proses pengembangan bisnis, peningkatan penggunaan website konten jual buku dan mempertahankan pengguna website selain peningkatan secara promosi maka diperlukan peningkatan layanan. Peningkatan layanan dilakukan supaya dapat meningkatkan traffic kunjungan website dengan menemukan alasan kenapa pengguna sering melakukan kunjungan website konten buku. Buku dicari banyak orang biasanya sesuai dengan yang dibutuhkan atau bisa jadi ada buku baru muncul atau bisa saja buku tersebut memiliki review yang bagus dan masih banyak lagi. Melalui analisa tersebut untuk bisa memudahkan pengguna mencari buku dan untuk meningkatkan traffic kunjungan website konten buku maka perlu sebuah sistem yang memberi saran sesuai kebutuhan pengguna dan juga pengguna baru. Sistem rekomendasi sangat tepat dalam menangani kasus seperti ini, dengan memberikan rekomendasi yang sesuai dengan data dan riwayat baca buku pengguna maka dapat memberikan dampak yang luar biasa dalam peningkatan traffic serta layanan. Hal ini memungkinkan pengguna dengan mudah mencari apa yang mereka inginkan dan mampu memberikan peningkatan penjualan buku.

### Problem Statement
- Metode sistem rekomendasi apa yang digunakan untuk kasus rekomendasi buku bagi pengguna website konten buku?
- Bagaimana cara sistem rekomendasi buku dalam menentukan rekomendasi ke pengguna berdasarkan rating buku?

### Goals

- Membuat sistem rekomendasi buku dengan metode Content Based Filtering dalam upaya peningkatan pengalaman pengguna untuk dapat menemukan buku dengan efisien.
- Memberi rekomendasi buku yang disukai oleh pengguna website konten buku melalui preferensi buku dengan rating yang populer.

Tujuan utama dari projek ini adalah membuat sistem yang mampu memberikan rekomendasi kepada pengguna website konten buku sesuai dengan preferensi pengguna dengan lebih efektif dan efisien sehingga mampu memudahkan pengguna serta peningkatan traffic kunjungan website konten buku.

## Data Understanding

Dataset yang digunakan berasal dari Kaggle dengan nama [Book Recommendation Datset](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset) yang diambil oleh Cai-Nicolas Ziegler melalui proses Crawling Data. Data tersebut diambil dan memiliki acuan website konten buku [Book Crossing Community](https://www.bookcrossing.com/?) disana dapat dijumpai banyak buku untuk dicari dikembangkan oleh komunitas dan store buku untuk melakukan transaksi jual beli. Terdiri dari 278,858 pengguna (anonimus akan tetapi memiliki informasi demografi), 1,149,780 rating dan 271,379 daftar buku. Semua data tersebut terbagi ke dalam 3 file berbeda berikut daftar serta parameter yang ada :
- File Users :

  File user ini merupakan file yang bersisi data pengguna berisi 278858 data pengguna. Semua nama pengguna dan ID pengguna sudah disamarkan karena hal ini berkaitan dengan masalah privasi. Awal sudah disebutkan bawah data ini hasil crawling data website resmi dan sudah mendapatkan persetujuan dari Ron Hornbaker, CTO of Humankind Systems (disebutkan di web Kaggle). Sehingga masalah privasi sangatlah ditekankan. Oleh karena itu pada projek ini berfokus pada User ID yang sudah diolah sesuai urutan data. Terdiri 3 fitur yaitu
  1. User ID

     Informasi ID pengguna yang sudah di anonimus dan diubah ke dalam bentuk integer sesuai dengan urutan data.

  2. Location

     Data demografi pengguna berisi tiga susunan yaitu lokasi alamat, kota dan negara dengan tipe data string.

  3. Age

     Data demografi pengguna berupa usia pengguna website BookCrossing dengan tipe data integer terdapat beberapa pengguna yang tidak mencantumkan usianya.

- File Books

  File Books terdiri dari 271379 data buku yang terdiri atas 8 kolom. Identifikasi buku umumnya diketahui dari nomor ISBN nya. Namun apabila terdapat ISBN yang tidak valid pada dataset ini ISBN tersebut dihilangkan. Beberapa informasi tambahan diambil dari Amazon Web Services. Berikut terdiri dari 8 fitur yang ada pada dataset Books yaitu
  1. ISBN
  
     Informasi nomor ISBN buku berisikan ID unik dari buku. Ada nomor ISBN yang sengaja dihilangkan oleh pembuat dataset karena termasuk nomor ISBN yang tidak valid. Pada dataset tipe datanya merupakan tipe data string.

  2. Book-Title
  
     Informasi mengenai judul buku dengan memiliki tipe data string.

  3. Book-Author
  
     Informasi mengenai penulis buku dengan memiliki tipe data string.

  4. Year-Of-Publication
  
     Informasi mengenai tahun dari buku tersebut dipublikasi memiliki tipe data integer.

  5. Publisher
  
     Informasi mengenai penerbit buku memiliki tipe data integer.

  6. Image-URL-S
  
     Informasi mengenai URL link gambar sampul depan buku dengan ukuran Small data ini berasal dari Amazon Website berisikan informasi URL.

  7. Image-URL-M
  
     Informasi mengenai URL link gambar sampul depan buku dengan ukuran Medium data ini berasal dari Amazon Website berisikan informasi URL.

  8. Image-URL-L
  
     Informasi mengenai URL link gambar sampul depan buku dengan ukuran Large data ini berasal dari Amazon Website berisikan informasi URL.


- File Ratings

  File Ratings terdiri dari 1,149,780 total rating. Rating buku dapat bersifat eksplisit yang di nilai dalam rentang 1 hingga 10 atau bersifat implisit yang dinilai dengan 0. Berikut terdiri dari 8 fitur yang ada pada dataset Books yaitu
  1. User ID

     Informasi ID pengguna yang sudah di anonimus dan diubah ke dalam bentuk integer sesuai dengan urutan data. Memiliki nilai unik dan terhubung dengan dataset Users.

  2. ISBN
  
     Informasi nomor ISBN buku berisikan ID unik dari buku. Ada nomor ISBN yang sengaja dihilangkan oleh pembuat dataset karena termasuk nomor ISBN yang tidak valid. Pada dataset tipe datanya merupakan tipe data string. ISBN ini terhubung dengan dataset Books.

  3. Book-Rating
  
     Informasi mengenai rating buku dengan memiliki tipe data integer. Memiliki nilai rentang 0 hingga 10.

Data-data diatas akan diperiksa terlebih dahulu untuk mendapatkan insight dari data sebelum melakukan ke tahapan data preparation. Penentuan variabel target akan menggunakan fitur Book-Rating dalam penentuan buku yang cocok serta sesuai dilihat juga kesamaan antar penulis maupun penerbit. Beberapa tahapan yang akan dilakukan untuk pemeriksaan dan pemahaman data diantaranya
1. Membaca Informasi dan Deskripsi Kolom pada Data
2. Melakukan Visualisasi Data untuk Cek Persebaran Data
3. Melakukan Exploratory Data Analysis Metode Univariate Analysis yaitu berdasarkan per variabel yang ada.

### Import Libraries

Beberapa library yang dibutuhkan dari mulai import data, pengolahan data, pembuatan model, evalusasi model hingga deployment.
"""

# Import Library Umum
import os, shutil, re
from shutil import copyfile
import zipfile
import pathlib
from pathlib import Path
import numpy as np
import pandas as pd
import requests
import warnings

# Commented out IPython magic to ensure Python compatibility.
# Import Library Visualisasi
# %matplotlib inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from matplotlib.image import imread
import seaborn as sns
from PIL import Image

!pip install faiss-cpu

!pip install faiss-gpu

!pip install scikit-surprise

# Import Library Preprocessing dan Machine Learning
import tensorflow as tf
import nltk
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler
from sklearn.metrics import confusion_matrix,classification_report, accuracy_score, roc_curve, auc
from sklearn.model_selection import train_test_split
from nltk.corpus import stopwords
nltk.download("stopwords")
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import TruncatedSVD
from scipy.sparse import csr_matrix
import faiss
from surprise import Reader, Dataset, accuracy
from surprise.prediction_algorithms import SVD, KNNBasic, KNNWithZScore
from sklearn.model_selection import train_test_split
from surprise.model_selection import GridSearchCV, cross_validate

"""### Import Dataset

Import dataset melalui platform kaggle secara langsung dengan menghubungkan nya melalui token API.
"""

# Mengambil data melalui google drive dengan melakukan autentikasi akun

from google.colab import drive
drive.mount('/content/drive')

# Install Libraru Kaggle
!pip install kaggle

# Upload file kaggle.json menggunakan token API akses melalui akun
from google.colab import files
files.upload()

# Hubungkan ke Kaggle melalui token API
!chmod 600 /content/kaggle.json

# Download dataset .zip ke dalam Google Drive
!kaggle datasets download -d arashnic/book-recommendation-dataset -p '/content/drive/My Drive/Dataset_MachineLearning/Dataset_Website_Buku'

# Cek Folder Google Drive
!ls '/content/drive/My Drive/Dataset_MachineLearning/Dataset_Website_Buku'

"""### Data Loading

Load dataset kemudian simpan ke dalam folder colab dan variabel agar mudah dipanggil.
"""

# Membuat direktori baru untuk menampung data gambar
!mkdir /content/website_buku

# Ekstrak Dataset
zip_ref = zipfile.ZipFile("/content/drive/My Drive/Dataset_MachineLearning/Dataset_Website_Buku/book-recommendation-dataset.zip", 'r')
zip_ref.extractall("/content/website_buku")
zip_ref.close()

# Dataset Website Buku
users_df = pd.read_csv("/content/website_buku/Users.csv")
books_df = pd.read_csv("/content/website_buku/Books.csv")
ratings_df = pd.read_csv("/content/website_buku/Ratings.csv")

print('Dataset Users')
print(users_df.head())
print('\n')
print('Dataset Books')
print(books_df.head())
print('\n')
print('Dataset Ratings')
print(ratings_df.head())

# Dataset Website Buku Cek Data Unik
users_df = pd.read_csv("/content/website_buku/Users.csv")
# books_df = pd.read_csv("/content/website_buku/Books.csv", dtype={'Book-Author': 'str'})
# books_df = pd.read_csv("/content/website_buku/Books.csv")
books_df = pd.read_csv("/content/website_buku/Books.csv", low_memory=False)
ratings_df = pd.read_csv("/content/website_buku/Ratings.csv")

print('Jumlah data pengguna pada website buku : ', len(users_df['User-ID'].unique()))
print('Jumlah data buku pada website buku     : ', len(books_df.ISBN.unique()))
print('Jumlah data rating website buku        : ', len(ratings_df['User-ID'].unique()))

# Cek Tipe Data
print('Tipe Data Users')
print(users_df.dtypes)
print('\n')
print('Tipe Data Books')
print(books_df.dtypes)
print('\n')
print('Tipe Data Ratings')
print(ratings_df.dtypes)

print('Jumlah baris data pengguna pada website buku : ', len(users_df))
print('Jumlah baris data buku pada website buku     : ', len(books_df))
print('Jumlah baris data rating website buku        : ', len(ratings_df))

"""Bisa dilihat secara jumlah data sedikit berbeda khususnya pada dataset Books hal tersebut bisa terjadi karena terdapat keterangan ISBN yang barangkali tidak valid sehingga dihilangkan.

### Exploratory Data Analysis - Deskripsi Variabel

Eksplorasi data untuk mengetahui info mengenai dataset beserta variabelnya.
"""

# Cek Info Kolom Dataset
print('Informasi Dataset Data Users')
print(users_df.info())
print('\n')
print('Informasi Dataset Data Books')
print(books_df.info())
print('\n')
print('Informasi Dataset Data Ratings')
print(ratings_df.info())

"""Jika dilihat melalui informasi diatas diketahui bahwa terdapat beberapa kolom yang memiliki nilai null di dua dataset yaitu dataset Users dan dataset Books. Kolom yang memiliki tipe data number hanya ada 3 sisanya bertipe data object. Tiga kolom yaitu User-ID, Age dan Book-Rating.

#### Dataset Describe
"""

# Cek Deskripsi Dataset
print('Deskripsi Dataset Data Users')
print(users_df.describe())
print('\n')
print('Deskripsi Dataset Data Books')
print(books_df.describe())
print('\n')
print('Deskripsi Dataset Data Ratings')
print(ratings_df.describe())

"""Fokus pada describe untuk mengetahui jumlah data, nilai rata-rata, standar deviasi, minimum, maksimum dan nilai kuartal. Selain itu untuk kolom string dataset Books ditampilkan jumlah, data unik, top dan frekuensi data.

#### Dataset Check Null
"""

# Cek Null Dataset
print('Cek Null Dataset Data Users')
print(users_df.isnull().sum())
print('\n')
print('Cek Null Dataset Data Books')
print(books_df.isnull().sum())
print('\n')
print('Cek Null Dataset Data Ratings')
print(ratings_df.isnull().sum())

"""Terdapat nilai null pada dataset users dan dataset books, sehingga diperlukan data cleaning.

#### Dataset Check NaN
"""

# Cek NaN Dataset
print('Cek NaN Dataset Data Users')
print(users_df.isna().sum())
print('\n')
print('Cek NaN Dataset Data Books')
print(books_df.isna().sum())
print('\n')
print('Cek NaN Dataset Data Ratings')
print(ratings_df.isna().sum())

"""Begitu juga dengan nilai NaN terdapat nilai NaN pada data sehingga perlu dilakukan cleaning untuk data NaN.

#### Dataset Check Duplicate
"""

# Cek Duplikat Data pada Dataset
print('Cek Duplikat Data pada Dataset Data Users   : ', users_df.duplicated().sum())
print('Cek Duplikat Data pada Dataset Data Books   : ', books_df.duplicated().sum())
print('Cek Duplikat Data pada Dataset Data Ratings : ', ratings_df.duplicated().sum())

"""Duplikat data tidak muncul karena semuanya bersifat unik untuk tiapbaris kolomnya.

#### Histogram Check Data Distribution

Persebaran data digunakan untuk mengetahui bagaimana data memiliki hubungan pada fitur variabel tertentu dengan nilai count. Persebaran data yang cocok ada pada kolom book-rating di dataset Ratings untuk melihat persebaran ratingnya.

##### Book-Rating

### Exploratory Data Analysis - Univariate Analysis

Eksplorasi data dengan metode Univariate Analysis yaitu analisis yang melibatkan satu variabel tunggal. Tujuan utamanya adalah untuk memahami distribusi, karakteristik, dan pola data dari satu variabel tersebut. Terdiri dari 3 dataset yaitu
- Dataset Users
- Dataset Books
- Dataset Ratings

Fokus analisis berputar pada 3 dataset diatas.

#### Variabel Users
"""

# Info Dataset Users
users_df.info()

# Cek Data Unik masing-masing kolom
print('Banyak data unik ID              : ', len(users_df['User-ID'].unique()))
print('Banyak data unik Lokasi pengguna : ', len(users_df.Location.unique()))
print('Banyak data unik Usia pengguna   : ', len(users_df.Age.unique()))

# Cek Data Unik Usia Pengguna
print('Banyak data unik Usia pengguna   : ', users_df.Age.unique())

"""##### Visualisasi Usia"""

# Membuat Bar Chart untuk mengetahui jumlah pengguna dengan usia tertentu
user_category_df = pd.read_csv("/content/website_buku/Users.csv")
bins = [0, 10, 20, 30, 40, 50, 60, 100]  # Definisikan batasan usia
labels = ['0-10', '11-20', '21-30', '31-40', '41-50', '51-60', '61+']  # Label untuk kategori usia
user_category_df['Age Category'] = pd.cut(user_category_df['Age'], bins=bins, labels=labels, right=False)

# Menghitung jumlah untuk setiap kategori usia
categorical_features = ['Age Category']
feature = categorical_features[0]

count = user_category_df[feature].value_counts()  # Menghitung jumlah untuk setiap kategori
percent = 100 * user_category_df[feature].value_counts(normalize=True)  # Menghitung persentase untuk setiap kategori

# Membuat DataFrame untuk menampilkan jumlah dan persentase
category_uni_df = pd.DataFrame({'jumlah sampel': count, 'persentase': percent.round(1)})

# Mengurutkan berdasarkan usia termuda
category_uni_df = category_uni_df.sort_index()

print(category_uni_df)

category_uni_df['jumlah sampel'].plot(kind='bar', title='Jumlah Sampel Berdasarkan Kategori Usia', color='skyblue')
plt.ylabel('Jumlah Sampel')
plt.xlabel('Kategori Usia')
plt.xticks(rotation=45)
plt.show()

"""Dari data diatas diketahui bahwa pengguna website buku memiliki lokasi tinggal yang berbeda ada sekitar 57339 datalokasi. Sedangkan usia pengguna beragam berjumlah 166 data hal ini mungkin terjadi karena tipe data bertipe float. Jadi perlu mengubah isi data agar memiliki pembulatan integer. Selain itu data usia yang mungkin tidak masuk akal seperti lebih dari 200 sehingga perlu dilakukan pengahpusan outlier serta penggantian nilai NaN yang jumlah nya pada usia cukup banyak.

Melalui bar chart diatas bisa terlihat bahwa kebanyakan pembaca adalah usia musa diantara 21-30 tahun. Kemungkinan memiliki kesamaan dalam hal buku bacaan maupun penulis kesukaan.

#### Variabel Books
"""

# Info Dataset Books
books_df.info()

# Cek Data Unik masing-masing kolom
print('Banyak data unik ISBN                   : ', len(books_df.ISBN.unique()))
print('Banyak data unik Judul Buku             : ', len(books_df['Book-Title'].unique()))
print('Banyak data unik Penulis                : ', len(books_df['Book-Author'].unique()))
print('Banyak data unik Tahun Publikasi        : ', len(books_df['Year-Of-Publication'].unique()))
print('Banyak data unik Penerbit               : ', len(books_df['Publisher'].unique()))
print('Banyak data unik Gambar Sampul Ukuran S : ', len(books_df['Image-URL-S'].unique()))
print('Banyak data unik Gambar Sampul Ukuran M : ', len(books_df['Image-URL-M'].unique()))
print('Banyak data unik Gambar Sampul Ukuran L : ', len(books_df['Image-URL-L'].unique()))

books_df_sorted = books_df.sort_values(by=['Year-Of-Publication', 'Book-Title'], ascending=[False, True])
books_df_sorted.head()

books_df['Year-Of-Publication'].unique()

"""Terdapat data tahun yang sepertinya tidak sesuai bahkan bisa dikatakan nilainya terbalik dengan Book-Author. Namun dalam kasus rekomendasi ini tidak begitu berpengaruh pada penentuan rekomendasi berdasarkan content based filtering karena memilih item tertentu saja yang cocok.

#### Variabel Ratings
"""

ratings_df.info()

ratings_df.head()

ratings_df.describe()

# Cek Data Unik masing-masing kolom
print('Banyak data unik ID pengguna : ', len(ratings_df['User-ID'].unique()))
print('Banyak data unik ISBN        : ', len(ratings_df.ISBN.unique()))
print('Banyak data unik Book-Rating : ', len(ratings_df['Book-Rating'].unique()))

"""##### Visualisasi Rating"""

feature = ['Book-Rating']
count = ratings_df[feature].value_counts()
percent = 100*ratings_df[feature].value_counts(normalize=True)
category_uni_df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(category_uni_df)
count.plot(kind='bar', title='Rating Buku');

"""Pada visualisasi diatas diketahui bahwa data rating 0 memiliki nilai yang banyak namun merujuk pada informasi yang ada di website [Kaggle Book](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset) bahwa sistem rating ini terdapat eksplisit dan implisit.
- Eksplisit adalah penilaian yang diberikan oleh pembaca atau pengguna yang secara langsung menilai buku dengan angka di suatu skala. Dalam hal ini, penilaian diberikan pada skala dari 1 hingga 10, di mana angka yang lebih tinggi menunjukkan penghargaan atau apresiasi yang lebih besar terhadap buku tersebut.
- Implisit adalah penilaian yang tidak diberikan secara langsung, namun dapat dihitung atau ditafsirkan berdasarkan tindakan pengguna, misalnya interaksi mereka dengan buku, seperti mengunduh atau membeli buku tersebut. Dalam hal ini, nilai 0 digunakan untuk menunjukkan bahwa tidak ada penilaian eksplisit yang diberikan oleh pembaca. Nilai 0 bisa berarti pembaca belum memberikan rating atau sistem tidak memiliki data penilaian untuk buku tersebut.

Bisa disimpulkan bahwa kebanyakan kemungkinan belum melakukan pemberian nilai rating atau datanya tidak terinput dengan baik.

## Data Preparation

Data preparation yaitu tahapan untuk melakukan transformasi data agar sesuai atau dapat dengan mudah digunakan ketika modeling machine learning. Bagian data preparation yang umum dilakukan ada beberapa tahapan diantaranya:
- Menghilangkan Outlier Dataset Users Kolom Usia
- Menghilangkan NaN/null Dataset Users Kolom Usia dengan interpolate() linier
- Pembulatan Nilai Integer Kolom Usia Dataset Users
- Membuat Kolom Kategori Usia pada Dataset Users
- Menghilangkan NaN/null Dataset Books dengan dropna()
- Mencari Buku yang Paling Populer
- Filter Pengguna yang Aktif dan Buku yang Terkenal

Tahapan diatas dijalankan secara berurutan dari mulai penghilangan outlier, menghapus nilai NaN kemudian menggabungkan beberapa fitur. Hanya beberapa fitur penting saja yang digunakan fokusnya pada data rating, kemudian perlu menggabungkan data judul buku serta kategori usia. Karena informasinya terbatas maka hubungan rating, judul buku serta usia dapat berdampak pada keputusan yang direkomendasikan sehigga perlu dibersihkan serta dipersiapkan dengan baik.

Berikut penjelasan tahapan diatas:
1. Menghilangkan Outlier dan Pembulatan Dataset Users Kolom Usia :
Tahapan ini dilakukan untuk menghilangkan data outlier seperti usia yang diatas rata-rata manusia normal seperti usia 200 tahun. Rasanya tidak masuk akan dengan usia 200 tahun sehingga perlu dipisahkan atau usianya dibatasi hingga 100 tahun saja. Pembulatan dilakukan agar nilai datanya stabil.
2. Menghilangkan NaN/null Dataset Users Kolom Usia dengan interpolate() Linier :
Tahapan dilakukan untuk menghilangkan nilai NaN maupun NULL pada data usia. Metode yang digunakan adalah interpolasi linier dengan cara mengisi nilai NaN dengan cara menghitung nilai rata-rata antara dua titik data yang ada di sekitar nilai yang hilang. Metode ini digunakan karena data NaN atau NULL pada fitur usia sangat banyak sehingga sangat disayangkan apabila datanya dibuang.
3. Pembulatan Nilai Integer Kolom Usia Dataset Users :
Pembulatan dilakukan agar nilai datanya stabil karena tipe data aslinya ada float.
4. Membuat Kolom Kategori Usia pada Dataset Users :
Tahapan ini dilakukan dalam upaya untuk membatasi nilai usia agar hanya terdapat beberapa kategori saja sehingga mudah untuk diidentifikasi hubungan usia dengan rekomendasi yang diberikan.
5. Menghilangkan NaN/null Dataset Books dengan dropna() :
Menghilangkan nilai NULL atau NaN pada dataset book melalui tahapan data understanding diketahui bahwa data nya kisaran 2 hingga 3. Sehingga apabila dihapus tidak akan berdampak banyak.
6. Mencari Buku yang Paling Populer :     
Tahapan ini dilakukan untuk mereduksi jumlah yang berisi ratusan ribuan bahkan jutaan bari data pada dataset rating diperkecil matriksnya agak mudah diolah. Hal ini berkaitan dengan keterbatasan teknologi yang penulis punya sehingga perlu mereduksi matriks dengan cara yang lebih tepat yaitu mengambil judul buku yang paling populer. Mencari buku yang paling populer dimulai dari penggabungan dataset Ratings dengan dataset Books.
7. Filter Pengguna yang Aktif dan Buku yang Terkenal :    
Tahapan filter ini dimaksudkan untuk menyaring mana pengguna yang aktif dan tidak sehingga fokusnya adalah pada buku dengan rating tinggi dengan pengguna yang aktif menilai. Sedangkan buku yang terkenal bisa menjadi acuan dengan rating yang tinggi. Tahapan ini dilakukan untuk memperkecil matriks namun mampu menghasilkan rekomendasi yang kuat.
8. Pembuatan Matriks Fitur Content dengan Pivot Table :
Tahapan ini dilakukan untuk membentuk matriks hubungan antara User-ID, Book-Title dengan Book-Rating. Acuan dari sistem rekomendasi content based filtering adalah 3 fitur ini yang nanti hasilnya adalah bentuk similarity atau kesamaan yang diolah menggunakan cosine-similarity. Walaupun menggunakan pivot bisa dibilang manual dan mungkin belum bisa maksimal menghasilkan sistem rekomendasi, namun tujuannya adalah untuk mereduksi ukuran matriks agar lebih mudah diolah pada modeling. Menggunakan TF-IDF Vectorizer dengan jumlah data sekitar 200ribuan bahkan dataset Ratings berjumlah 1juta memiliki keterbatasan device untuk mengolah. Jauh lebih mudah dan ringan menggunakan pivot menggabungkan ketiga fitur User-ID, Book-Title dan Book-Rating.

#### Menghilangkan Outlier dan Pembulatan Dataset Users Kolom Usia
"""

# Membuat variabel baru untuk menyimpan hasil olahan outlir
users_outlier_df = users_df

# Menyaring outlier usia (misalnya usia lebih dari 100 dianggap tidak valid)
users_outlier_df['Age'] = users_outlier_df['Age'].apply(lambda x: x if x <= 100 else None)

# Cet Outlier
# Cek Data Unik Usia Pengguna
print('Banyak data unik Usia pengguna   : ', users_outlier_df.Age.unique())

"""#### Menghilangkan NaN/null Dataset Users Kolom Usia dengan interpolate() linier"""

# Membuat variabel baru untuk menyimpan hasil olahan outlir
users_clean_df = users_outlier_df

# Menggunakan interpolasi linier untuk mengisi nilai NaN
users_clean_df['Age'] = users_clean_df['Age'].interpolate(method='linear')

# Menghilangkan sisa NaN dengan dropna()
users_clean_df = users_clean_df.dropna(subset=['Age'])

# Cek NaN Dataset
print('Cek NaN Dataset Data Users')
print(users_clean_df.isnull().sum())

# Cek Data Unik Usia Pengguna
print('\nBanyak data unik Usia pengguna   : ', users_clean_df.Age.unique())

# Cek info Dataset
print('\n')
print(users_clean_df.info())

"""#### Pembulatan Nilai Integer Kolom Usia Dataset Users"""

# Membuat variabel baru untuk menyimpan hasil olahan outlir
users_int_df = users_clean_df.copy()

# Mengubah nilai menjadi integer
users_int_df.loc[:, 'Age'] = users_int_df['Age'].apply(lambda x: int(x) if x is not None else None)

# Cek perubahan nilai usia
print(users_int_df.head())

"""#### Membuat Kolom Kategori Usia pada Dataset Users"""

# Membuat Ketgoti Usia
users_category_df = users_int_df.copy()

# Mendefinisikan Batasan Usia
bins = [0, 10, 20, 30, 40, 50, 60, 101]

# Label untuk Kategori Usia
labels = ['0-10', '11-20', '21-30', '31-40', '41-50', '51-60', '61+']

# Membentuk Kolom Baru
users_category_df['Age-Category'] = pd.cut(users_category_df['Age'], bins=bins, labels=labels, right=False)

# Menampilan Dataset Users Kategori
print(users_category_df.head())
print('\n')
print(users_category_df.info())

"""#### Menghilangkan NaN/null Dataset Books dengan dropna()"""

# Membuat variabel baru untuk menyimpan hasil olahan outlir
books_clean_df = books_df.copy()

# Menghilangkan sisa NaN dengan dropna()
books_clean_df = books_clean_df.dropna()

# Cek NaN Dataset
print('Cek NaN Dataset Data Books')
print(books_clean_df.isnull().sum())

# Cek info Dataset
print('\n')
print(books_clean_df.info())

"""#### Mencari Buku yang Paling Populer

Tahapan ini dilakukan untuk mereduksi jumlah yang berisi ratusan ribuan bahkan jutaan bari data pada dataset rating diperkecil matriksnya agak mudah diolah. Hal ini berkaitan dengan keterbatasan teknologi yang penulis punya sehingga perlu mereduksi matriks dengan cara yang lebih tepat yaitu mengambil judul buku yang paling populer. Mencari buku yang paling populer dimulai dari penggabungan dataset Ratings dengan dataset Books.
"""

# Menambahkan title dan menggabungkan dengan dataset Ratings
rating_with_title=ratings_df.merge(books_clean_df,on='ISBN')

# Membentuk tabel baru groupby Book-Title kemudian menghitung jumlah ratingnya berdasarkan Book-Title
count_ratings_df=rating_with_title.groupby('Book-Title').count()['Book-Rating'].reset_index()
count_ratings_df.rename(columns={'Book-Rating':'count_ratings'},inplace=True)
count_ratings_df

# Membentuk tabel baru groupby Book-Title kemudian menghitung rata-rata ratingnya berdasarkan Book-Title
avg_rating_df=rating_with_title.groupby('Book-Title').mean(numeric_only=True)['Book-Rating'].reset_index()
avg_rating_df.rename(columns={'Book-Rating':'avg_ratings'},inplace=True)
avg_rating_df

# Membuat tabel baru untuk dapat menemukan buku yang populer berdasarkan banyaknya rating dan rata-rata nilai rating
popular_book_df=count_ratings_df.merge(avg_rating_df,on='Book-Title')
popular_book_df

# Mencari dan mensortir judul buku yang popular dengan total rating lebih dari 200
# berdasarkan urutan rata-rata rating dan mengambil 50 data saja
popular_book_df = popular_book_df[popular_book_df['count_ratings']>=200].sort_values('avg_ratings',ascending=False).head(50)

# Menggabungkan buku popular dengan books_clean_df dengan memilih
# kolom 'Book-Title','Book-Author','Image-URL-M','count_ratings' dan 'avg_ratings'.
popular_book_df = popular_book_df.merge(books_clean_df,on='Book-Title').drop_duplicates('Book-Title')[['Book-Title','Book-Author','Image-URL-M','count_ratings','avg_ratings']]

popular_book_df.shape

popular_book_df

"""#### Filter Pengguna yang Aktif dan Buku yang Terkenal

Filter ini dimaksudkan untuk menyaring mana pengguna yang aktif dan tidak sehingga fokusnya adalah pada buku dengan rating tinggi dengan pengguna yang aktif menilai. Sedangkan buku yang terkenal bisa menjadi acuan dengan rating yang tinggi. Tahapan ini dilakukan untuk memperkecil matriks namun mampu menghasilkan rekomendasi yang kuat.

Membuat matriks hubungan User-ID dengan Book-Title melalui Book-Rating setelah itu bisa dibuatkan mode untuk melihat similaritynya. Matriks yang ada dibuat sedemikian rupa agar memiliki matriks yang kecil tidak ratusan ribu atau jutaan.
"""

# Membentuk tabel kolom x yang terdiri dari User-ID dan Book-Rating banyaknya lebih dari 200
kolom_x = rating_with_title.groupby('User-ID').count()['Book-Rating']>200
active_users_df = kolom_x[kolom_x].index

# Membuat tabel dengan filter berdasarkan active_user_df
filtered_ratings_df = rating_with_title[rating_with_title['User-ID'].isin(active_users_df)]

filtered_ratings_df.shape

filtered_ratings_df.head()

# Membentuk tabel kolom y yang terdiri dari Book-Title dan Book-Rating banyaknya lebih dari 50
kolom_y = filtered_ratings_df.groupby('Book-Title').count()['Book-Rating']>=50
famous_books_df = kolom_y[kolom_y].index

# Membuat tabel dengan filter berdasarkan active_user_df
final_ratings_df = filtered_ratings_df[filtered_ratings_df['Book-Title'].isin(famous_books_df)]

final_ratings_df.shape

final_ratings_df

"""#### Pembuatan Matriks Fitur Content dengan Pivot Table

Tahapan ini dilakukan untuk membentuk matriks hubungan antara User-ID, Book-Title dengan Book-Rating. Acuan dari sistem rekomendasi content based filtering adalah 3 fitur ini yang nanti hasilnya adalah bentuk similarity atau kesamaan yang diolah menggunakan cosine-similarity. Walaupun menggunakan pivot bisa dibilang manual dan mungkin belum bisa maksimal menghasilkan sistem rekomendasi, namun tujuannya adalah untuk mereduksi ukuran matriks agar lebih mudah diolah pada modeling. Menggunakan TF-IDF Vectorizer dengan jumlah data sekitar 200ribuan bahkan dataset Ratings berjumlah 1juta memiliki keterbatasan device untuk mengolah. Jauh lebih mudah dan ringan menggunakan pivot menggabungkan ketiga fitur User-ID, Book-Title dan Book-Rating.
"""

# Memebentuk pivot yang terdiri kolom x User-ID dan kolom y Book-Title dengan isi data Book-Rating
matriks_vector = final_ratings_df.pivot_table(index='Book-Title',columns='User-ID',values='Book-Rating')

matriks_vector.fillna(0,inplace=True)

matriks_vector.shape

matriks_vector

matriks_vector.index

"""## Modeling and Result

Bagian model development akan berfokus pada pembuatan model dengan

- Content Based Filtering yang terdiri dari tahapan
  1. Cosine Similarity

      Pada tahap ini, kita mengukur kemiripan antar item (misalnya, buku atau produk) berdasarkan karakteristik mereka menggunakan Cosine Similarity. Cosine similarity adalah metode untuk mengukur seberapa mirip dua vektor berdasarkan sudut antara keduanya, bukan panjangnya. Ini sangat berguna untuk menghitung kemiripan antara dua item meskipun panjang (magnitudo) fitur item berbeda. Untuk cosine similarity tinggal dijalankan karena matrik_vector sudah dibuat berdasarkan pivot User-ID, Book-Title dan Book-Rating

  2. Rekomendasi

      Rekomendasi terdiri beberapa bagian membuat tiga fungsi yaitu similarity yang dibagi dua berdasarkan jarak terdekat dan menggunakan korelasi koefisien paerson. Terakhir membentuk fungsi rekomendasi.
      - Fungsi Jarak Terdekat : membuat fungsi kemiripan suatu item berdasarkan jarak terdekatnya.
      - Fungsi Koefisien Korelasi Paerson : membuat fungsi berdasarkan koefisien korelasi paerson.

### Content Based Filtering

#### Cosine Similarity
"""

cosine_sim_score = cosine_similarity(matriks_vector)
cosine_sim_score

cosine_sim_score.shape

# Mengubah pivot menjadi dataframe yang lebih mudah diakses
matriks_vector_copy = matriks_vector.copy()
matriks_vector_df = matriks_vector_copy.reset_index()
matriks_vector_df

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa judul buku
cosine_sim_score_df = pd.DataFrame(cosine_sim_score, index=matriks_vector_df['Book-Title'], columns=matriks_vector_df['Book-Title'])
print('Shape:', cosine_sim_score_df.shape)

# Melihat similarity matrix pada setiap resto
cosine_sim_score_df.sample(5, axis=1).sample(10, axis=0)

"""#### Rekomendasi

###### Fungsi Similarity berdasarkan Jarak Terdekat
"""

def sim_distance(cosine_sim_score, book1, book2):
    # Menentukan rating yang sama antara book1 dan book2
    common_ratings = (cosine_sim_score.loc[book1] != 0) & (cosine_sim_score.loc[book2] != 0)

    # Jika tidak ada rating bersama, kembalikan 0
    if not common_ratings.any():
        return 0

    # Menghitung jarak Euclidean hanya jika ada rating bersama
    distance = np.sqrt(np.sum((cosine_sim_score.loc[book1][common_ratings] - cosine_sim_score.loc[book2][common_ratings]) ** 2))

    # Menghindari pembagian oleh nol jika distance terlalu kecil (0)
    if distance == 0:
        return 1  # Jika jaraknya 0, artinya sangat mirip, kembalikan nilai 1

    return 1 / (1 + distance)  # Invers jarak untuk mendapatkan kemiripan

"""###### Fungsi Similarity berdasarkan Korelasi Koefisien Paerson"""

def sim_paerson(cosine_sim_score, book1, book2):
    # Menentukan rating yang sama antara book1 dan book2
    common_ratings = (cosine_sim_score.loc[book1] != 0) & (cosine_sim_score.loc[book2] != 0)

    # Jika tidak ada rating bersama, kembalikan 0
    if not common_ratings.any():
        return 0

    # Menyaring rating yang cocok
    ratings1 = cosine_sim_score.loc[book1][common_ratings]
    ratings2 = cosine_sim_score.loc[book2][common_ratings]

    # Menghindari pembagian oleh nol atau perhitungan korelasi dengan varians 0
    if np.std(ratings1) == 0 or np.std(ratings2) == 0:
        return 0  # Jika salah satu variansnya 0, kembalikan 0, artinya tidak ada variasi dalam data

    # Menghitung korelasi Pearson
    return np.corrcoef(ratings1, ratings2)[0, 1]  # Koefisien Korelasi Paerson

"""###### Fungsi Rekomendasi"""

def book_recommendation(book_name, similarity_func=sim_paerson):
    if book_name not in matriks_vector.index:
        print(f"'{book_name}' not found in the dataset.")
        return

    # Mencari indeks buku dalam DataFrame
    index = np.where(matriks_vector.index == book_name)[0][0]

    # Menghitung skor kemiripan dengan buku lain
    similarity_scores = [(similarity_func(matriks_vector, book_name, other_book), other_book)
                         for other_book in matriks_vector.index if other_book != book_name]

    # Mengurutkan hasil berdasarkan skor kemiripan
    similar_items = sorted(similarity_scores, key=lambda x: x[0], reverse=True)[:5]

    print(f"Recommendations for '{book_name}':")
    for score, book_title in similar_items:
        print(book_title)

"""#### Result Top-5 Recommendation"""

print('Result Top-5 Recommendation by Distance & Paersoncorrcoef\n')
print('Rekomendasi Similarity berdasarkan Jarak Terdekat')
book_recommendation('Animal Dreams', similarity_func=sim_distance)
print('\nRekomendasi Similarity berdasarkan Koefisien Korelasi Paerson')
book_recommendation('Animal Dreams', similarity_func=sim_paerson)

"""## Evaluation

#### Precision & Recall

- Precision mengukur seberapa banyak rekomendasi yang relevan dibandingkan dengan total rekomendasi yang diberikan.
- Recall mengukur seberapa banyak item yang relevan yang berhasil direkomendasikan oleh sistem dibandingkan dengan total item relevan yang ada.
"""

def precision_recall_at_k(recommended_items, relevant_items, k):
    recommended_top_k = recommended_items[:k]
    relevant_top_k = [item for item in recommended_top_k if item in relevant_items]

    precision = len(relevant_top_k) / k if k > 0 else 0
    recall = len(relevant_top_k) / len(relevant_items) if len(relevant_items) > 0 else 0

    return precision, recall

"""#### F1-Score

F1-Score adalah harmonik mean dari precision dan recall, yang memberi gambaran tentang keseimbangan antara keduanya. F1-Score sangat berguna ketika Anda ingin menjaga keseimbangan antara precision dan recall, terutama ketika ada ketidakseimbangan antara keduanya.
"""

def f1_score(precision, recall):
    if precision + recall == 0:
        return 0
    return 2 * (precision * recall) / (precision + recall)

"""### Evaluasi Rekomendasi"""

# Ambil 5 rekomendasi teratas untuk 'Animal Dreams'
recommended_books = ['1984', 'A Map of the World', 'Absolute Power', 'All Around the Town', 'American Gods']

# Tentukan buku relevan berdasarkan rating > 3 (misalnya)
relevant_books = ['1984', 'Animal Dreams', 'A Map of the World', 'American Gods']

# Hitung precision dan recall
precision, recall = precision_recall_at_k(recommended_books, relevant_books, k=5)
f1 = f1_score(precision, recall)

print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")

"""Jika dilihat melalui hasil precision, recall dan f1-score rekomendasi buku dengan buku yang relevan memiliki rekomendasi yang cukup dekat sekitar 60 hingga 70%. Membuktikan bahwa sistem rekomendasi yang dibuat memiliki kedekatan terhadap penilaian yang relevan.

## Referensi
[1] Kommineni Madhuri. etc, "Machine Learning based Efficient Recommendation System for Book Selection using User based Collaborative Filtering Algorithm", IEEE, 2020.

[2] Mathew Praveena. etc, "Book Recommendation System through Content Based and Collaborative Filtering Method", IEEE, 2016.

[3] Shanker Tewari Anand. etc, "Book Recommendation System Based on Combine Features of Content Based Filtering, Collaborative Filtering and Association Rule Mining", IEEE, 2014.
"""

!pip freeze requirements.txt